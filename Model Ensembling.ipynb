{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents:<a class=\"anchor\" id=\"contents\"></a>\n",
    "* [Setup and Data preparation](#setup)\n",
    "* [Loading Models to Ensemble](#loading)\n",
    "* [Building Ensembles](#buildingensembles)\n",
    "* [Evaluating Ensembles](#evaluatingensembles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data preparation <a class=\"anchor\" id=\"setup\"></a>\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext jupyternotify\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve\n",
    "from keras import models, layers, optimizers, regularizers\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import to_categorical\n",
    "from keras import Input\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import os, shutil\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from keras_gcnn.layers import GConv2D, GBatchNorm\n",
    "from keras_gcnn.layers.pooling import GroupPool\n",
    "\n",
    "#Loading my custom functions from a separate Jupyter notebook\n",
    "from ipynb.fs.full.my_functions import build_and_compile_model, build_and_compile_model_GCNN, fit_model_to_generator, plot_auc, area_under_ROC_curve\n",
    "from ipynb.fs.full.my_functions import plot_results,plot_graphs, plot_smooth, plot_smooth_graphs, fit_model_to_directory_generator, evaluate_auc\n",
    "from ipynb.fs.full.my_functions import build_and_compile_dense_model, crop, memory_required, count_conv_layers\n",
    "from ipynb.fs.full.my_functions import model_ensemble_evaluation, acc_comparison, save_history, load_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.nasnet import NASNetMobile\n",
    "from keras.applications.xception import Xception\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D, Input, Concatenate, GlobalMaxPooling2D\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation and generator setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32768 images belonging to 2 classes.\n",
      "Found 32768 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "base_dir = \"C:/GitRepos/FINAL PROJECT DATA/Histopathologic Cancer Detection/WholePCamSetFromGithub/converted_images/\"\n",
    "tr_dir = os.path.join(base_dir, \"train\")\n",
    "va_dir = os.path.join(base_dir, \"valid\")\n",
    "te_dir = os.path.join(base_dir, \"test\")\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batch_size = 64 \n",
    "targ_size = (96,96)\n",
    "classification = \"binary\"\n",
    "\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    va_dir,\n",
    "    target_size=targ_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=classification)\n",
    "\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "    te_dir,\n",
    "    target_size=targ_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Models To Ensemble <a class=\"anchor\" id=\"loadingGCNN\"></a>\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Highest performing P4M Alternate blocks model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_filters = 12\n",
    "weight_decay = 1e-4\n",
    "P4M_Altblocks6 = build_and_compile_dense_model(initial_filters,growth_rate=8,dense_blocks=6,conv_layers=1,\n",
    "                                           is_gconv=True,gconv_type=\"D4\",padding=\"same\",dropout=0.2,img_size=96,\n",
    "                                           opt=\"DenseSGD\",weight_decay=weight_decay,output=\"sigmoid\",labels=1,bc_model=False)\n",
    "P4M_Altblocks6.load_weights(\"../model_saves/PCAM/PCAM_Dense/P4M_Altblocks4BestWeights229epochs.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Highest performing P4M-BC model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_filters = 3\n",
    "weight_decay = 1e-4\n",
    "P4M_BC3 = build_and_compile_dense_model(initial_filters,growth_rate=3,dense_blocks=6,conv_layers=3,\n",
    "                                           is_gconv=True,gconv_type=\"D4\",padding=\"same\",dropout=0.2,img_size=96,\n",
    "                                           opt=\"DenseSGD\",weight_decay=weight_decay,output=\"sigmoid\",labels=1,bc_model=True)\n",
    "P4M_BC3.load_weights(\"../model_saves/PCAM/PCam_Dense/P4M_BC3BestWeights224epochs.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_filters = 24\n",
    "weight_decay = 1e-4 \n",
    "CNN_Best = build_and_compile_dense_model(initial_filters,growth_rate=24,dense_blocks=6,conv_layers=3,\n",
    "                                           is_gconv=False,gconv_type=\"D4\",padding=\"same\",dropout=0.2,img_size=96,\n",
    "                                           opt=\"DenseSGD\",weight_decay=weight_decay,output=\"sigmoid\",labels=1,bc_model=True)\n",
    "CNN_Best.load_weights(\"../model_saves/PCAM/PCam_Dense/CNN_BestBestWeights141epochs.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Xception/NASNet model sourced from Kaggle, taken for experimentation purposes. \n",
    "https://www.kaggle.com/greg115/histopathologic-cancer-detector-lb-0-958"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model taken from https://www.kaggle.com/greg115/histopathologic-cancer-detector-lb-0-958\n",
    "\n",
    "input_shape = (96, 96, 3)\n",
    "inputs = Input(input_shape)\n",
    "\n",
    "xception = Xception(include_top=False, input_shape=input_shape)  \n",
    "nas_net = NASNetMobile(include_top=False, input_shape=input_shape)\n",
    "\n",
    "outputs = Concatenate(axis=-1)([GlobalAveragePooling2D()(xception(inputs)),\n",
    "                                GlobalAveragePooling2D()(nas_net(inputs))])\n",
    "outputs = Dropout(0.5)(outputs)\n",
    "outputs = Dense(1, activation='sigmoid')(outputs)\n",
    "\n",
    "#Pretrained but also trained on PYCAM afterwards for about 12 epochs by me.\n",
    "preTrainedModel = Model(inputs, outputs)\n",
    "preTrainedModel.compile(optimizer=Adam(lr=0.0001, decay=0.00001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "preTrainedModel.load_weights(\"../model_saves/PCAM/pretrainedModelFinal.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Ensembles <a class=\"anchor\" id=\"buildingensembles\"></a>\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens = [P4M_BC3,P4M_Altblocks6]\n",
    "ens2 = [P4M_BC3,CNN_Best]\n",
    "ens3 = [P4M_BC3,preTrainedModel]\n",
    "\n",
    "ens4 = [P4M_BC3, P4M_Altblocks6, CNN_Best]\n",
    "ens5 = [P4M_BC3, P4M_Altblocks6, preTrainedModel]\n",
    "ens6 = [P4M_BC3, CNN_Best, preTrainedModel]\n",
    "\n",
    "ens7 = [P4M_BC3,P4M_Altblocks6, CNN_Best, preTrainedModel]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Ensembles <a class=\"anchor\" id=\"evaluatingensembles\"></a>\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6592/6592 [==============================] - 13s 2ms/step\n",
      "6592/6592 [==============================] - 10s 1ms/step\n",
      "val scores:  [0.9120145631067961, 0.9044296116504854]\n",
      "weights [0.5020878570235511, 0.497912142976449]\n",
      "Ensemble scores: ([0.9106924019607843, 0.904296875, 0.9153645833333334], [0.9705873727207059, 0.9653383141383142, 0.9727790031790032])\n"
     ]
    }
   ],
   "source": [
    "print(\"Ensemble scores:\",model_ensemble_evaluation(ens,test_generator, weighted=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6592/6592 [==============================] - 10s 2ms/step\n",
      "6592/6592 [==============================] - 14s 2ms/step\n",
      "val scores:  [0.9118628640776699, 0.9001820388349514]\n",
      "weights [0.5032231059020511, 0.4967768940979489]\n",
      "Ensemble scores: ([0.9109987745098039, 0.899203431372549, 0.9210707720588235], [0.9706987857871879, 0.9587126783447024, 0.9750973545269976])\n"
     ]
    }
   ],
   "source": [
    "print(\"Ensemble scores:\",model_ensemble_evaluation(ens2,test_generator, weighted=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble Three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6592/6592 [==============================] - 11s 2ms/step\n",
      "6592/6592 [==============================] - 12s 2ms/step\n",
      "val scores:  [0.9050364077669902, 0.8073422330097088]\n",
      "weights [0.5285258681785967, 0.4714741318214033]\n",
      "Ensemble scores: ([0.9121859681372549, 0.8044577205882353, 0.9088158700980392], [0.9710595847516397, 0.9415384711596657, 0.9711987578180499])\n"
     ]
    }
   ],
   "source": [
    "print(\"Ensemble scores:\",model_ensemble_evaluation(ens3,test_generator, weighted=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble Four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6592/6592 [==============================] - 12s 2ms/step\n",
      "6592/6592 [==============================] - 8s 1ms/step\n",
      "6592/6592 [==============================] - 11s 2ms/step\n",
      "val scores:  [0.8986650485436893, 0.9033677184466019, 0.9165655339805825]\n",
      "weights [0.33056191060766693, 0.33229172479214325, 0.33714636460018965]\n",
      "Ensemble scores: ([0.8993566176470589, 0.9044500612745098, 0.9094669117647058, 0.9239047181372549], [0.9580732113398553, 0.9656385737886108, 0.9704416093893364, 0.9761926718261242])\n"
     ]
    }
   ],
   "source": [
    "print(\"Ensemble scores:\",model_ensemble_evaluation(ens4,test_generator, weighted=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble Five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6592/6592 [==============================] - 10s 2ms/step\n",
      "6592/6592 [==============================] - 8s 1ms/step\n",
      "6592/6592 [==============================] - 12s 2ms/step\n",
      "val scores:  [0.917627427184466, 0.908373786407767, 0.7996055825242718]\n",
      "weights [0.3494915645944072, 0.34596718280563904, 0.3045412525999538]\n",
      "Ensemble scores: ([0.9094669117647058, 0.9034926470588235, 0.8060278799019608, 0.9139476102941176], [0.9705011203622216, 0.9648682663017941, 0.9410835249765556, 0.9733200040183655])\n"
     ]
    }
   ],
   "source": [
    "print(\"Ensemble scores:\",model_ensemble_evaluation(ens5,test_generator, weighted=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble Six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6592/6592 [==============================] - 11s 2ms/step\n",
      "6592/6592 [==============================] - 12s 2ms/step\n",
      "6592/6592 [==============================] - 12s 2ms/step\n",
      "val scores:  [0.9059466019417476, 0.8956310679611651, 0.8056735436893204]\n",
      "weights [0.34747192645604236, 0.34351544772211556, 0.3090126258218421]\n",
      "Ensemble scores: ([0.9121859681372549, 0.9008501838235294, 0.8053002450980392, 0.9158624387254902], [0.971287811950585, 0.9591961299427535, 0.9420490075191347, 0.9769506100231218])\n"
     ]
    }
   ],
   "source": [
    "print(\"Ensemble scores:\",model_ensemble_evaluation(ens6,test_generator, weighted=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble Seven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6592/6592 [==============================] - 11s 2ms/step\n",
      "6592/6592 [==============================] - 8s 1ms/step\n",
      "6592/6592 [==============================] - 11s 2ms/step\n",
      "6592/6592 [==============================] - 12s 2ms/step\n",
      "val scores:  [0.9121662621359223, 0.9042779126213593, 0.8983616504854369, 0.8029429611650486]\n",
      "weights [0.2593039803355039, 0.2570615377980939, 0.2553797058950364, 0.22825477597136573]\n",
      "Ensemble scores: ([0.9103860294117647, 0.9045649509803921, 0.8992800245098039, 0.8059895833333334, 0.9200367647058824], [0.970480145082907, 0.9654041323730757, 0.9584806363504418, 0.9414159798170825, 0.9771637213885354])\n"
     ]
    }
   ],
   "source": [
    "print(\"Ensemble scores:\",model_ensemble_evaluation(ens7,test_generator, weighted=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
